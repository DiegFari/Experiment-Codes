---
title: "research-project"
output: html_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

## Loading necessary libraries
library(dplyr)
library(ggplot2)
library(tidyverse)
library(broom)
library(lme4)
library(boot)
library(ordinal)
```

## Research Project

### Data Formatting

```{r}
# Set working directory to source file location

# Documentation function to read in PCIbex Farm results files (source: https://doc.pcibex.net/advanced-tutorial/12_examining-data.html#reading-in-results):
read.pcibex <- function(filepath, fun.col=function(col,cols){cols[cols==col]<-paste(col,"Ibex",sep=".");return(cols)}) {
  n.cols <- max(count.fields(filepath,sep=",",quote=NULL),na.rm=TRUE)
  
  cols <- c()
    con <- file(filepath, "r")
    while ( TRUE ) {
      line <- readLines(con, n = 1, warn=FALSE)
      if ( length(line) == 0) {
        break
      }
      m <- regmatches(line,regexec("^# (\\d+)\\. (.+)\\.$",line))[[1]]
      if (length(m) == 3) {
        index <- as.numeric(m[2])
        value <- m[3]
        if (is.function(fun.col)){
         cols <- fun.col(value,cols)
        }
        cols[index] <- value
        if (index == n.cols){
          break
        }
      }
    }
    
    close(con)
    
    return(read.csv(filepath, comment.char="#", header=FALSE, col.names=cols, colClasses="character"))
}

# Function to format PCIbex Farm results files:
format.pcibex <- function(results, group) {
  formatted_results <- results %>% 
    # 1. Rename columns for easier handling
    rename(Subject = MD5.hash.of.participant.s.IP.address, ItemNumber = Order.number.of.item, ItemType = Label, Age = age, Gender = gender, Occupation = occupation, Nationality = nationality) %>% 
    # 2. Remove irrelevant columns
    select(-Results.reception.time, -Controller.name, -Inner.element.number, -Latin.Square.Group, -Comments, -PennElementType) %>% 
    # 3. Remove irrelevant sections of the experiment
    filter(ItemType %in% c('personal-info', 'experiment', 'manipulation-check', 'sd-bias')) %>% 
    # 4. Remove rows generated by the timer (we will calculate RT ourselves)
    filter(PennElementName != 'RT') %>%
    # 5. Remove other unnecessary rows generated by PCIbex
    filter(Value != 'End' | ItemType == 'experiment') %>%
    filter(Value != 'Start' | ItemType %in% c('experiment', 'personal-info')) %>%
    # 7. Add an additional column with the specific group (high sd vs. low sd)
    mutate(Group = group) %>% 
    # 9. Some columns were not added correctly and were instead added as extra rows. Shift them into their own columns.
    mutate(Question = ifelse(ItemType == 'experiment', Age, NA), Age = ifelse(ItemType == 'personal-info', Age, NA)) %>% 
    mutate(QuestionType = ifelse(ItemType == 'experiment', Gender, NA), Gender = ifelse(ItemType == 'personal-info', Gender, NA)) %>% 
    mutate(Occupation = ifelse(ItemType == 'personal-info', Occupation, NA), Nationality = ifelse(ItemType == 'personal-info', Nationality, NA)) %>% 
    # 10. Repeat the same value for these columns for all rows specific to a subject
    group_by(Subject) %>%
    mutate(Age = first(Age), Gender = first(Gender), Occupation = first(Occupation), Nationality = first(Nationality)) %>%
    ungroup()
  
  return(formatted_results)
}

# Read in result files:
results_high_sd <- read.pcibex("results_high_sd.csv") %>% format.pcibex('high-sd')

results_low_sd <- read.pcibex("results_low_sd.csv") %>% format.pcibex('low-sd')

results <- bind_rows(results_high_sd, results_low_sd)

results
```

### Demographics Analysis

```{r}
# Age percentages:
age_summary <- results %>%
  # 1. Select only one value per subject 
  distinct(Subject, Age) %>%
  # 2. Prepare data for comparison 
  mutate(Age = as.numeric(trimws(Age))) %>% 
  # 3. Divide into groups
  mutate(Age = ifelse(Age > 30, "Over 30", "30 and Under")) %>% 
  # 4. Calculate percentage and sort
  group_by(Age) %>%
  summarize(
    Count = n(), 
    Percentage = round((n() / n_distinct(results$Subject)) * 100, 1)
  ) %>%
  arrange(desc(Percentage))

print(age_summary)

# Gender percentages:
gender_summary <- results %>%
  # 1. Select only one value per subject 
  distinct(Subject, Gender) %>% 
  # 2. Prepare data for comparison 
  mutate(Gender = tolower(Gender)) %>% 
  # 3. Calculate percentage and sort
  group_by(Gender) %>%
  summarize(
    Count = n(), 
    Percentage = round((n() / n_distinct(results$Subject)) * 100, 1)
  ) %>%
  arrange(desc(Percentage))

print(gender_summary)

# Occupation percentages:
occupation_summary <- results %>%
  # 1. Select only one value per subject 
  distinct(Subject, Occupation) %>% 
  # 2. Prepare data for comparison 
  mutate(Occupation = tolower(Occupation), Occupation = case_when(grepl("student", Occupation) ~ "student", TRUE ~ "worker")) %>%
  # 3. Calculate percentage and sort
  group_by(Occupation) %>%
  summarize(
    Count = n(), 
    Percentage = round((n() / n_distinct(results$Subject)) * 100, 1)
  ) %>%
  arrange(desc(Percentage))

print(occupation_summary)

# Nationality percentages:
nationality_summary <- results %>%
  # 1. Select only one value per subject 
  distinct(Subject, Nationality) %>% 
  # 2. Prepare data for comparison 
  mutate(Nationality = tolower(Nationality), Nationality = case_when(grepl("italian", Nationality) ~ "italian", grepl("italien", Nationality) ~ "italian", grepl("italy", Nationality) ~ "italian", TRUE ~ "other")) %>% 
  # 3. Calculate percentage and sort
  group_by(Nationality) %>%
  summarize(
    Count = n(), 
    Percentage = round((n() / n_distinct(results$Subject)) * 100, 1)
  ) %>%
  arrange(desc(Percentage))

print(nationality_summary)

# Group percentages:
group_summary <- results %>%
  # 1. Select only one value per subject 
  distinct(Subject, Group) %>%
  # 2. Calculate percentage and sort
  group_by(Group) %>%
  summarize(
    Count = n(), 
    Percentage = round((n() / n_distinct(results$Subject)) * 100, 1)
  ) %>%
  arrange(desc(Percentage))

print(group_summary)
```

### Response Times Calculation

```{r}
# RTs for every question for every subject:
results_with_rt <- results %>%
  # 1. Prepare EventTime for numerical comparison
  mutate(EventTime = as.numeric(trimws(EventTime))) %>% 
  # 2. Select only experiment rows marked as "Start" and "End" 
  filter(ItemType == "experiment" & Value %in% c("Start", "End")) %>%
  # 3. Calculate RT by subtracting EventTime values from "Start" and "End"
  select(Subject, Question, Value, EventTime) %>%
  pivot_wider(names_from = Value, values_from = EventTime) %>%
  mutate(RT = as.character(End - Start))

results <- results %>% 
  # 4. Add new RT column to results
  left_join(results_with_rt, by = c("Subject", "Question")) %>%
  # 5. Remove experiment rows marked as "Start" and "End" (they are now irrelevant)
  filter(!Value %in% c("Start", "End") | ItemType == "personal-info") %>% 
  # 6. Remove irrelevant columns
  select(-Start, -End, -EventTime)

results
```

### Answer Switches Calculation

```{r}
# Answer switches for every question for every subject:
results_answer_switches <- results %>%
  # 1. Select only recorded answers for every experiment questions
  filter(ItemType == "experiment" & Parameter == "Choice") %>% 
  # 2. Count how many instances per subject per question
  count(Subject, Question)

results <- results %>% 
  # 3. Add answer switches count to results
  left_join(results_answer_switches, by = c("Subject", "Question")) %>%
  # 4. Rename new column to AnswerSwitches
  rename(AnswerSwitches = n)

# Calculating the mean answer switches per subject
subject_mean_as <- results %>%
  mutate(AnswerSwitches = as.numeric(AnswerSwitches)) %>%  
  group_by(Subject) %>% 
  summarize(SubjectMeanAS = mean(AnswerSwitches, na.rm = TRUE))

# Join this column to the original dataset
results <- results %>%
  left_join(subject_mean_as, by = "Subject")

results
```

### Mouse Speed Calculation

#### Formatting the mouse data

In order to calculate the mouse speed, we are following the approach suggested by PCIBEX for mouse tracking studies (source: <https://www.pcibex.net/wiki/mousetracker-element/>). In short, we first create three new columns to our dataframe (timestamps, xpos, ypos). These will store, respectively, the time and the position of the mouse on the x and y axis. Based on these new columns, we than calculate the mouse speed.

```{r format-mouse-data, cache=TRUE}
# Our dataframe 'results' has a column 'Value' where the mouse-tracking data are stored

timestamps_get_response <- vector()   # Vector to store timestamp
xpos_get_response <- vector()         # Vector to store pos x
ypos_get_response <- vector()         # Vector to store pos y

# For each row of the dataframe
for (row in 1:nrow(results)) {
  pos <- data.frame(time=numeric(0), x=numeric(0), y=numeric(0)) # Initialize the vector
  
  # Check if the row's 'Parameter' column is "Move"
  if (results[row, "Parameter"] == "Move") {
    
    time <- 0  # Initialize time
    stream <- as.character(results[row, "Value"]) # Get the stream of data from 'Value' column
    
    # Extract x and y positions from the data stream
    pos <- data.frame(
      time = c(time),
      x = as.numeric(gsub("^x(\\d+)y.+$", "\\1", stream)),
      y = as.numeric(gsub("^.+y(\\d+)w.+$", "\\1", stream))
    )
    
    ptime <- time # Previous time
    px <- pos[1, "x"] # Initial x position
    py <- pos[1, "y"] # Initial y position
    
    # Loop through positions in the stream (split by 't')
    for (s in (strsplit(stream, 't')[[1]][-1])) {
      # Extract and separate coordinates and time from the stream
      row <- strsplit(gsub("^(\\d+)([+-]\\d+)([+-]\\d+)$", "\\1 \\2 \\3", s), ' ')
      
      # Calculate new time and new positions
      ntime <- as.numeric(ptime + as.numeric(row[[1]][1]))
      nx <- as.numeric(px + as.numeric(row[[1]][2]))
      ny <- as.numeric(py + as.numeric(row[[1]][3]))
      
      # Append the data to the position dataframe
      pos <- rbind(pos, data.frame(time = ntime, x = nx, y = ny))
      
      # Update previous time and position
      ptime <- ntime
      px <- nx
      py <- ny
    }
  }
  
  # Create the format for timestamps and positions
  times <- toString(pos[["time"]])
  timestamp <- paste("[", times, "]", sep = "")
  timestamps_get_response <- c(timestamps_get_response, timestamp)
  
  xpos <- toString(pos[["x"]])
  xpos_str <- paste("[", xpos, "]", sep = "")
  xpos_get_response <- c(xpos_get_response, xpos_str)
  
  ypos <- toString(pos[["y"]])
  ypos_str <- paste("[", ypos, "]", sep = "")
  ypos_get_response <- c(ypos_get_response, ypos_str)
}

# Add the new columns to the original dataframe
results$timestamps <- timestamps_get_response
results$xpos <- xpos_get_response
results$ypos <- ypos_get_response

results
```

#### Calculating the mouse speed

We need to calculate the mouse-speed between each time stamp. Then we calculate an average for each participant.

```{r}
# Constructing the functions that we need 

# This function turns chr values into numerics
parse_vector <- function(str) {
  as.numeric(unlist(strsplit(gsub("\\[|\\]", "", str), ", ")))
}


# This function calculates the distance covered between two points
calculate_distance <- function(x1, x2, y1, y2) {
  distance <- sqrt((x2 - x1)^2 + (y2 - y1)^2)
  return (distance)
}

# This function calculates the velocity between two points
calculate_speed <- function(x1, x2, y1, y2, t1, t2) {
  # First we check that t2 is bigger than t1
  if (t2 > t1) {
    speed <- calculate_distance(x1, x2, y1, y2)/(t2-t1)
    return(speed)
  } 
  # Otherwise we return a NA value
  else {
    return(NA)
  }
}

# This function calculates the average velocity for every "Move" row in the results
calculate_average_velocity <- function(results) {
  results$AvgMouseSpeed <- NA  # Initialize the column
  
  for (i in 1:nrow(results)) {
    # Process only rows where Parameter == "Move"
    if (results[i, "Parameter"] == "Move") {
      # Transform strings into numeric vectors
      timestamps <- parse_vector(results[i, "timestamps"])
      xpos <- parse_vector(results[i, "xpos"])
      ypos <- parse_vector(results[i, "ypos"])
      
      velocities <- c()  # Initialized an empty vector to store the velocities
      
      for (j in 1:(length(timestamps) - 1)) {
        speed <- calculate_speed(xpos[j], xpos[j+1], ypos[j], ypos[j+1], timestamps[j], timestamps[j+1])
        velocities <- c(velocities, speed)
      }
      
      # Assign average speed for the current row
      results$AvgMouseSpeed[i] <- mean(velocities, na.rm = TRUE)
    }
  }
  
  return(results)  
}


# Add the average velocities back to results
results <- calculate_average_velocity(results)

# Remove unnecessary data
results <- select(results, -timestamps, -xpos, -ypos)

results
```

### Control Questions Check

```{r}
# Check if any subjects failed to answer the control questions correctly:
results_positive_control_question <- results %>%
  # 1. Filter for positive control question responses
  filter(QuestionType == 'control' & Parameter == "Choice" & Question == "How often do you send and receive messages or emails?") 

results_negative_control_question <- results %>%
  # 1. Filter for negative control question responses
  filter(QuestionType == 'control' & Parameter == "Choice" & Question == "How often do you publicly share your online banking credentials on social media or public forums?") 

# Suspicious (i.e., failed) responses for control questions:
negative_choices <- c("Never", "Few times")
positive_choices <- c("Sometimes", "Often", "Really often")

# Check if any subjects failed to answer the control questions correctly:
results_failed_positive <- results %>%
  # 1. Filter for failed positive control question responses
  filter(QuestionType == "control", Parameter == "Choice", Question == "How often do you send and receive messages or emails?", Value %in% negative_choices) %>% 
  # 2. Pull problematic subjects
  pull(Subject)

results_failed_negative <- results %>%
  # 1. Filter for failed negative control question responses
  filter(QuestionType == "control", Parameter == "Choice", Question == "How often do you publicly share your online banking credentials on social media or public forums?", Value %in% positive_choices) %>% 
  # 2. Pull problematic subjects
  pull(Subject)
  
results_failed <- union(results_failed_positive, results_failed_negative)

results_failed

results_failed_subjects <- results %>% 
  filter(Subject %in% results_failed)

results_failed_subjects

results <- results %>% 
  filter(!Subject %in% results_failed)

results
```

### Remove subjects too far from the threshold in all the three metrics measured

```{r}
# Fisrt, mouse-speed

# Filtering the dataset for the rows needed and calculating the mean average mouse speed:
subject_mean_mouse_speed <- results %>%
  filter(ItemType == "experiment") %>%
  select(Subject, ItemNumber, AvgMouseSpeed) %>%
  distinct() %>% 
  filter(!is.na(AvgMouseSpeed)) %>% 
  group_by(Subject) %>%
  summarize(AvgMouseSpeedMeanRT = mean(AvgMouseSpeed, na.rm = TRUE))

# Calculating Median (M) and MAD
M <- median(subject_mean_mouse_speed$AvgMouseSpeedMeanRT, na.rm = TRUE)
MAD <- mad(subject_mean_mouse_speed$AvgMouseSpeedMeanRT, constant = 1, na.rm = TRUE)

# Defining the threshold
threshold <- M + 3 * MAD

# Filtering subjects out of the threshold
outlier_subjects <- subject_mean_mouse_speed$Subject[!is.na(subject_mean_mouse_speed$AvgMouseSpeedMeanRT) & subject_mean_mouse_speed$AvgMouseSpeedMeanRT > threshold]

outlier_subject_rows <- subject_mean_mouse_speed[subject_mean_mouse_speed$Subject %in% outlier_subjects, ]

outlier_subject_rows

results <- results[!results$Subject %in% outlier_subjects, ]

# Second, RT

# Filtering the dataset for the rows needed and calculating the average RT:
subject_mean_rt <- results %>%
  filter(ItemType == "experiment") %>%
  select(Subject, ItemNumber, RT) %>%
  distinct() %>% 
  mutate(RT = as.numeric(RT)) %>%  
  group_by(Subject) %>%
  summarize(SubjectMeanRT = mean(RT, na.rm = TRUE))

# Calculating Median (M) and MAD
M <- median(subject_mean_rt$SubjectMeanRT, na.rm = TRUE)
MAD <- mad(subject_mean_rt$SubjectMeanRT, constant = 1, na.rm = TRUE)

# Defining the threshold
threshold <- M + 3 * MAD

# Filtering subjects out of the threshold
outlier_subjects <- subject_mean_rt$Subject[!is.na(subject_mean_rt$SubjectMeanRT) & subject_mean_rt$SubjectMeanRT > threshold]

outlier_subject_rows <- subject_mean_rt[subject_mean_rt$Subject %in% outlier_subjects, ]

outlier_subject_rows

results <- results[!results$Subject %in% outlier_subjects, ]

# Third, answer switches

# Filtering the dataset for the rows needed
subject_mean_as <- results %>%
  filter(ItemType == "experiment") %>%
  select(Subject, ItemNumber, AnswerSwitches) %>%
  distinct() %>%
  group_by(Subject) %>%
  summarize(SubjectMeanAS = mean(AnswerSwitches, na.rm = TRUE))

# Calculating Median (M) and MAD
M <- median(subject_mean_as$SubjectMeanAS, na.rm = TRUE)
MAD <- mad(subject_mean_as$SubjectMeanAS, constant = 1, na.rm = TRUE)

# Defining the threshold
threshold <- M + 3 * MAD

# Filtering subjects out of the threshold
outlier_subjects <- subject_mean_as$Subject[!is.na(subject_mean_as$SubjectMeanAS) & subject_mean_as$SubjectMeanAS > threshold]

outlier_subject_rows <- subject_mean_as[subject_mean_as$Subject %in% outlier_subjects, ]

outlier_subject_rows

results <- results[!results$Subject %in% outlier_subjects, ]

results
```

### Controlling the Manipulation Check

```{r}
manipulation_check_answers <- results %>%
  filter(ItemType == "manipulation-check")

manipulation_check_scale <- c(
  "Strongly disagree" = 1,
  "Disagree" = 2,
  "Not agree nor disagree" = 3,
  "Agree" = 4,
  "Strongly agree" = 5
)

manipulation_check_answers <- manipulation_check_answers %>%
  mutate(MC = manipulation_check_scale[Value])

manipulation_check_t_test <- t.test(MC ~ Group, data = manipulation_check_answers)

manipulation_check_t_test
```

### Controlling the SD bias questionnaire

```{r}

sd_results <- filter(results, ItemType == "sd-bias")

sd_results 

sd_bias_scale <- c(
  "25" = "False",
  "26" = "False",
  "27" = "False",
  "28" = "False",
  "29" = "True",
  "30" = "False",
  "31" = "True",
  "32" = "False",
  "33" = "True", 
  "34" = "True", 
  "35" = "False",
  "36" = "False", 
  "37" = "True"
)

sd_results <- sd_results %>%
  mutate(SDBias = ifelse(sd_bias_scale[ItemNumber] == Value, 1, 0))

sd_results

sd_bias_scores <- sd_results %>%  
  group_by(Subject, Group)  %>%
  summarize(sd_bias_score = sum(SDBias))


sd_bias_scores

sd_bias_t_test <- t.test(sd_bias_score ~ Group, data = sd_bias_scores)

sd_bias_t_test
```

### Constructing models

```{r}
# We get the avg mouse speed per subject per experiment question
subject_group_avg_mouse_speed <- results %>%
  filter(ItemType == "experiment") %>%
  select(Subject, Group, ItemNumber, AvgMouseSpeed) %>%
  distinct() %>%
  filter(!is.na(AvgMouseSpeed))

subject_group_avg_mouse_speed

# We graph avg mouse speed to check best transformation for normal distribution:
ggplot(subject_group_avg_mouse_speed, aes(x = log(AvgMouseSpeed))) +
  geom_density(fill = "lightblue", alpha = 0.7) +
  theme_minimal() +
  labs(title = "Distribution of Log AMS (Density Plot)", x = "Log AMS", y = "Density")

ggplot(subject_group_avg_mouse_speed, aes(x = sqrt(AvgMouseSpeed))) +
  geom_density(fill = "lightblue", alpha = 0.7) +
  theme_minimal() +
  labs(title = "Distribution of Sqrt AMS (Density Plot)", x = "Sqrt AMS", y = "Density")

ggplot(subject_group_avg_mouse_speed, aes(x = (AvgMouseSpeed)^(1/3))) +
  geom_density(fill = "lightblue", alpha = 0.7) +
  theme_minimal() +
  labs(title = "Distribution of Cubed AMS (Density Plot)", x = "Cubed AMS", y = "Density")

ggplot(subject_group_avg_mouse_speed, aes(x = (1/AvgMouseSpeed))) +
  geom_density(fill = "lightblue", alpha = 0.7) +
  theme_minimal() +
  labs(title = "Distribution of Inverse AMS (Density Plot)", x = "Inverse AMS", y = "Density")

# Log transformation yields the best fit for normal distribution
m1 <- lmer(log(AvgMouseSpeed) ~ Group + (1 | Subject) + (1 | ItemNumber),
     data = subject_group_avg_mouse_speed)

summary(m1)

hist(residuals(m1), main="Residuals of the model for AMS")
plot(density(residuals(m1)), main="Residuals of the model for AMS")
qqnorm(residuals(m1), main="Residuals of the model for AMS")
qqline(residuals(m1))

# We get the RT per subject per experiment question
subject_group_rt <- results %>%
  filter(ItemType == "experiment") %>%
  select(Subject, Group, ItemNumber, RT) %>%
  distinct() %>%
  mutate(RT = as.numeric(RT))

subject_group_rt

# We graph RT to check best transformation for normal distribution:
ggplot(subject_group_rt, aes(x = log(RT))) +
  geom_density(fill = "lightblue", alpha = 0.7) +
  theme_minimal() +
  labs(title = "Distribution of Log RT (Density Plot)", x = "Log RT", y = "Density")

ggplot(subject_group_rt, aes(x = sqrt(RT))) +
  geom_density(fill = "lightblue", alpha = 0.7) +
  theme_minimal() +
  labs(title = "Distribution of Sqrt RT (Density Plot)", x = "Sqrt RT", y = "Density")

ggplot(subject_group_rt, aes(x = (RT)^(1/3))) +
  geom_density(fill = "lightblue", alpha = 0.7) +
  theme_minimal() +
  labs(title = "Distribution of Cubed RT (Density Plot)", x = "Cubed RT", y = "Density")

ggplot(subject_group_rt, aes(x = (1/RT))) +
  geom_density(fill = "lightblue", alpha = 0.7) +
  theme_minimal() +
  labs(title = "Distribution of Inverse RT (Density Plot)", x = "Inverse RT", y = "Density")

m2 <- lmer(log(RT) ~ Group + (1 | Subject) + (1 | ItemNumber),
     data = subject_group_rt)

summary(m2)

hist(residuals(m2), main="Residuals of the model for log RT")
plot(density(residuals(m2)), main="Residuals of the model for log RT")
qqnorm(residuals(m2), main="Residuals of the model for log RT") 
qqline(residuals(m2))

subject_group_as <- results %>%
  filter(ItemType == "experiment") %>%
  select(Subject, Group, ItemNumber, AnswerSwitches) %>%
  distinct()

subject_group_as

m3 <- glmer(AnswerSwitches ~ Group + (1 | Subject + ItemNumber),
     data = subject_group_as,
     family = poisson)

summary(m3)
```
